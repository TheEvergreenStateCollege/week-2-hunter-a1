{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: otter-grader in d:\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from otter-grader) (2.18.4)\n",
      "Requirement already satisfied: google-api-python-client in d:\\anaconda3\\lib\\site-packages (from otter-grader) (2.47.0)\n",
      "Requirement already satisfied: jupyter-client in d:\\anaconda3\\lib\\site-packages (from otter-grader) (5.2.3)\n",
      "Requirement already satisfied: ipykernel in d:\\anaconda3\\lib\\site-packages (from otter-grader) (4.8.2)\n",
      "Requirement already satisfied: pdfkit in d:\\anaconda3\\lib\\site-packages (from otter-grader) (1.0.0)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from otter-grader) (1.11.0)\n",
      "Requirement already satisfied: nbformat in d:\\anaconda3\\lib\\site-packages (from otter-grader) (4.4.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from otter-grader) (0.23.0)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda3\\lib\\site-packages (from otter-grader) (3.12)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (from otter-grader) (2.2.2)\n",
      "Requirement already satisfied: nbconvert in d:\\anaconda3\\lib\\site-packages (from otter-grader) (5.3.1)\n",
      "Requirement already satisfied: python-on-whales in d:\\anaconda3\\lib\\site-packages (from otter-grader) (0.6.0)\n",
      "Requirement already satisfied: dill in d:\\anaconda3\\lib\\site-packages (from otter-grader) (0.3.4)\n",
      "Requirement already satisfied: PyPDF2 in d:\\anaconda3\\lib\\site-packages (from otter-grader) (1.27.12)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from otter-grader) (2.10)\n",
      "Requirement already satisfied: google-auth-oauthlib in d:\\anaconda3\\lib\\site-packages (from otter-grader) (0.5.1)\n",
      "Requirement already satisfied: gspread in d:\\anaconda3\\lib\\site-packages (from otter-grader) (5.3.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests->otter-grader) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->otter-grader) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->otter-grader) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->otter-grader) (2018.4.16)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->otter-grader) (0.20.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->otter-grader) (2.7.3)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->otter-grader) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->otter-grader) (2.6.6)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->otter-grader) (0.1.0)\n",
      "Requirement already satisfied: traitlets in d:\\anaconda3\\lib\\site-packages (from jupyter-client->otter-grader) (4.3.2)\n",
      "Requirement already satisfied: jupyter_core in d:\\anaconda3\\lib\\site-packages (from jupyter-client->otter-grader) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=13 in d:\\anaconda3\\lib\\site-packages (from jupyter-client->otter-grader) (17.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda3\\lib\\site-packages (from jupyter-client->otter-grader) (2.7.3)\n",
      "Requirement already satisfied: tornado>=4.1 in d:\\anaconda3\\lib\\site-packages (from jupyter-client->otter-grader) (5.0.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in d:\\anaconda3\\lib\\site-packages (from ipykernel->otter-grader) (6.4.0)\n",
      "Requirement already satisfied: ipython_genutils in d:\\anaconda3\\lib\\site-packages (from nbformat->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in d:\\anaconda3\\lib\\site-packages (from nbformat->otter-grader) (2.6.0)\n",
      "Requirement already satisfied: pytz>=2011k in d:\\anaconda3\\lib\\site-packages (from pandas->otter-grader) (2018.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in d:\\anaconda3\\lib\\site-packages (from pandas->otter-grader) (1.14.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib->otter-grader) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: mistune>=0.7.4 in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: pygments in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (0.2.3)\n",
      "Requirement already satisfied: bleach in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (1.4.2)\n",
      "Requirement already satisfied: testpath in d:\\anaconda3\\lib\\site-packages (from nbconvert->otter-grader) (0.3.1)\n",
      "Requirement already satisfied: pydantic in d:\\anaconda3\\lib\\site-packages (from python-on-whales->otter-grader) (1.9.0)\n",
      "Requirement already satisfied: typeguard in d:\\anaconda3\\lib\\site-packages (from python-on-whales->otter-grader) (2.13.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from python-on-whales->otter-grader) (4.64.0)\n",
      "Requirement already satisfied: typer in d:\\anaconda3\\lib\\site-packages (from python-on-whales->otter-grader) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->otter-grader) (1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib->otter-grader) (1.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->otter-grader) (1.56.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->otter-grader) (3.19.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client->otter-grader) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client->otter-grader) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in d:\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client->otter-grader) (4.8)\n",
      "Requirement already satisfied: decorator in d:\\anaconda3\\lib\\site-packages (from traitlets->jupyter-client->otter-grader) (4.3.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (0.8.1)\n",
      "Requirement already satisfied: backcall in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (0.1.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (0.3.9)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (0.7.4)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (1.0.15)\n",
      "Requirement already satisfied: jedi>=0.10 in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipykernel->otter-grader) (39.1.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in d:\\anaconda3\\lib\\site-packages (from bleach->nbconvert->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in d:\\anaconda3\\lib\\site-packages (from pydantic->python-on-whales->otter-grader) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\lib\\site-packages (from pydantic->python-on-whales->otter-grader) (3.10.0.2)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.7\" in d:\\anaconda3\\lib\\site-packages (from tqdm->python-on-whales->otter-grader) (5.4.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda3\\lib\\site-packages (from typer->python-on-whales->otter-grader) (8.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->otter-grader) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client->otter-grader) (0.4.8)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=4.0.0->ipykernel->otter-grader) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.2.0 in d:\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda3\\lib\\site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in d:\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.7\"->tqdm->python-on-whales->otter-grader) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in d:\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer->python-on-whales->otter-grader) (4.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "httplib2 0.20.4 has requirement pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > \"3.0\", but you'll have pyparsing 2.2.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install otter-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Simple Linear Regression\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this lab, we will review some of the details of how linear regression works as described in Lectures 12 and 13.\n",
    "\n",
    "We will also show you how to do linear regression using various real world tools including:\n",
    "- (Question 1) `seaborn`\n",
    "- (Question 2) analytic solution\n",
    "- (Question 3) `scipy.optimize`\n",
    "- (Question 4 & 5) `scikit-learn`\n",
    "\n",
    "In real world data science work, you are far more likely to use something similar to the `seaborn` and `scikit-learn` approaches, but it is important to know how to use the formulaic and `scipy.optimize` approaches so that you understand what is really going on.\n",
    "\n",
    "**This assignment should be completed and submitted by 11:59 PM PDT on Tuesday, October 12th.**\n",
    "\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk to others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_List collaborators here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all DeprecationWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the tips dataset that we also explored in Lab 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab 6, we fit a **constant** model to this dataset, meaning our model was $\\hat{y} = \\theta$. In other words, given the set of tips `tips['tip']`, we tried to find a summary statistic $\\theta$ that best represented our set of tips. To find the value of $\\theta$, we minimized the following empirical risk:\n",
    "\n",
    "$$R(\\theta) = \\frac{1}{n}\\sum_{i = 1}^n L(y_i, \\theta)$$\n",
    "\n",
    "Here, $\\mathcal{D} = \\{y_1, y_2, ..., y_n \\}$ refers to our set of `tips` values.\n",
    "\n",
    "We looked at two different loss functions:\n",
    "\n",
    "- $L_2(y_i, \\hat{y_i}) = (y_i - \\hat{y_i})^2$\n",
    "\n",
    "- $L_1(y_i, \\hat{y_i}) = \\left| y_i - \\hat{y_i} \\right|$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "By contrast, in this lab, we're interested in studying the **relationship between two variables**. Specifically, we're interested in the relationship between the `total_bill` column and `tip` column. Our goal will be to predict tip ($y$) from total_bill ($x$), i.e., we want to find values of $a$ and $b$ so that given $x$, predict $y$ as\n",
    "$$\\boxed{\\hat{y} = a + bx}$$\n",
    "We will now explore different ways to obtain the optimal values of $a, b$, called $\\hat{a}, \\hat{b}$, where $\\hat{y} = \\hat{a} + \\hat{b}x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's run `sns.lmplot`, which will both provide a scatterplot of `tip` vs `total_bill` and display the least-squares line of best fit. We will look into solving for the line of best fit in three different ways: manually using the formula from lecture, `scipy.optimize`, and `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data = tips, x = \"total_bill\", y = \"tip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 – Analytic Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Lecture 12](http://ds100.org/sp21/lecture/lec12/), we derived the following expression for the line of best fit.\n",
    "\n",
    "$$\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$$\n",
    "\n",
    "where $\\bar{x}$, $\\bar{y}$, $SD(x)$, $SD(y)$ correspond to the means and standard deviations of $x$ and $y$, respectively, and $r$ is the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a\n",
    "\n",
    "Assign `x_bar`, `y_bar`, `std_x`, `std_y`, and `r`, for our dataset. Note: Make sure to use `np.std`, and not `<Series name>.std()`.\n",
    "\n",
    "- Hint: Remember, in our case, `y` is `tip`, and `x` is `total_bill`.\n",
    "- Hint: You may find `np.corrcoef` handy in computing `r`. Note that the output of `np.corrcoef` is a matrix, not a number, so you'll need to collect the correlation coefficient by indexing into the returned array.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar = ...\n",
    "y_bar = ...\n",
    "std_x = ...\n",
    "std_y = ...\n",
    "r = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, set `b_hat` and `a_hat` correctly, in terms of the variables you defined above. \n",
    "\n",
    "- Hint: Try and match the slope and intercept in $\\hat{y_i} = \\hat{a} + \\hat{b}x_i$ to the slope and intercept in $\\hat{y_i} = \\bar{y} + r \\frac{SD(y)}{SD(x)} (x_i - \\bar{x})$.\n",
    "\n",
    "- Hint: You may want to define `a_hat` in terms of `b_hat`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat = ...\n",
    "a_hat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "Now, use `a_hat` and `b_hat` to predict the tip for a total bill amount of $20. Store your result in `predicted_20`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_20 = ...\n",
    "predicted_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1d\n",
    "Assign `regression` to be a `pd.Series` of predicted $y$ values (i.e., predicted `\"tip\"` values) for the observed total bills (`tips[\"total_bill\"]`). You will need to use `a_hat`, `b_hat`, and `tips[\"total_bill\"]`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you defined `regression` correctly, the following cell will generate a scatter plot of `tip` vs. `total_bill`, along with the line of best fit you just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='total_bill', y='tip', data=tips)\n",
    "plt.plot(tips[\"total_bill\"], regression, color = 'r')\n",
    "plt.xlabel('total_bill')\n",
    "plt.ylabel('tip');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $r$, the correlation coefficient between `tips` and `total_bill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**In the cell below**, comment on the value of $r$, and what it means in the context of the above scatter plot.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 – Using Scipy Minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.minimize` is a powerful method that can determine the optimal value of a variety of different functions. In practice, it is used to minimize functions that have no (or difficult to obtain) analytical solutions (it is a **numerical method**).\n",
    "\n",
    "It is overkill for our simple example, but nonetheless, we will show you how to use it, as it will become useful in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the function `l2_tip_risk` which computes the empirical risk for a given choice of `a` and `b`. That is, it computes\n",
    "\n",
    "$$R(a, b) = \\frac{1}{n} \\sum_{i = 1}^n(y_i - (a + b x_i))^2$$\n",
    "\n",
    "where, again, $x$ and $y$ refer to `\"total_bill\"` and `\"tip\"`.\n",
    "\n",
    "As a reminder: Risk refers to the average loss on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_tip_risk(a, b):\n",
    "    \"\"\"Returns average l2 loss between regression line for intercept a \n",
    "       and slope b\"\"\"\n",
    "    y_hat = a + b * tips[\"total_bill\"]\n",
    "    return np.mean((tips[\"tip\"] - y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out different `a` and `b` values. Observe that if you pick values close to the ones from the earlier part of this lab then the risk is lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_tip_risk(0.9, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minimize` function we saw in Lab 6 can also minimize functions of multiple variables. There's one quirk, however, which is that the function has to accept its parameters as a single list.\n",
    "\n",
    "For example, consider the multivariate $f(u, v) = u^2 - 2 u v - 3 v + 2 v^2$. It turns out this function's minimum is at $(1.5, 1.5)$. To minimize this function, we create `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta):\n",
    "    u = theta[0]\n",
    "    v = theta[1]\n",
    "    return u**2 - 2 * u * v - 3 * v + 2 * v**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(f, x0 = [0.0, 0.0]) \n",
    "\n",
    "# As an aside: x0 is the \"initial guess\" for the optimal theta. Minimize iteratively updates theta.\n",
    "# We will study an iterative algorithm for function minimization in the coming weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Define `l2_tip_risk_list` which is exactly like `l2_tip_risk` except that it takes in a single list of 2 variables rather than two separate variables. For example `l2_tip_risk_list([2, 3])` should return the same value as `l2_tip_risk(2, 3)`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_tip_risk_list(theta):\n",
    "    \"\"\"Returns average l2 loss between regression line for intercept a \n",
    "       and slope b\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Now, set `minimized` to the result of calling `minimize` to optimize this risk function.\n",
    "\n",
    "- Hint: Make sure to set `x0`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of your call to `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will print out the values of `a_hat` and `b_hat` computed from both methods (\"manual\" refers to the technique in Question 1). If you've done everything correctly, these should be very close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_hat_scipy: ', minimized['x'][0])\n",
    "print('a_hat_manual: ', a_hat)\n",
    "print('\\n')\n",
    "print('b_hat_scipy: ', minimized['x'][1])\n",
    "print('b_hat_manual: ', b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason these don't match past the first 5 decimal places is due to the fact that `scipy.minimize` is a numerical method, meaning it approximates the optimal value using an iterative procedure. You shouldn't worry about the tiny differences in solutions from different runs of `minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 – Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another way to fit a linear regression model is to use scikit learn, an industry standard package for machine learning applications. \n",
    "\n",
    "To do so, we first create a `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `model` is like a \"blank slate\" for a linear model. Now, we need to tell `model` to \"fit\" itself to the data. Essentially, this is doing exactly what you did in the previous part of this lab (creating a risk function and finding the parameters that minimize that risk).\n",
    "\n",
    "<i>Note: `X` needs to be a matrix (or DataFrame), as opposed to a single array (or Series). This is because `sklearn.linear_model` is robust enough to be used for multiple regression, which we will look at in Question 4.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X = tips[['total_bill']], y= tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model exists, we can look at the a_hat and b_hat values it found, which are given in the attributes `intercept` and `coef`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `scikit-learn` linear regression model to make predictions, you can use the `model.predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[20]]) # 20 needs to be a 2D array since the X above was a 2D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code tells us that `model` predicts a tip of $\\$3.02$ given a total bill amount of $\\$20$. This is the same as doing `a_hat + b_hat * 20` as in Question 1c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Create a linear regression plot using `model.predict`. It should look very similar (if not the same) as your plot from Question 1d.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_tip = ...\n",
    "sns.scatterplot(x='total_bill', y='tip', data=tips)\n",
    "plt.plot(tips[\"total_bill\"],  predicted_tip, color = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 – Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous parts we showed how to establish relationships between one independent explanatory variable and one response variable. However, with real-world problems you will often want to use **multiple features** to model and predict a response variable. To do so, we will use multiple linear regression, as discussed in [Lecture 13](http://ds100.org/sp21/lecture/lec13/). Multiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to the observed data. Formally, the model for multiple linear regression, given $p$ features is:\n",
    "\n",
    "$$y_i = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + … + \\theta_p x_p $$\n",
    "\n",
    "Please note that we have been using the terms **features**, **independent variables**, and **explanatory variables** interchangeably. Usually “features” are used in the context of machine learning when you are trying to make predictions. “Independent variables” and “explanatory variables” are mainly found in statistics, econometrics and other related fields which focus on understanding the relationship between a set of variables.  \n",
    "\n",
    "\n",
    "For example, consider the plot below which shows fuel efficiency vs. engine power for several models of automobiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we load the fuel dataset, and drop any rows that have missing data\n",
    "vehicle_data = sns.load_dataset('mpg').dropna()\n",
    "vehicle_data = vehicle_data.sort_values('horsepower', ascending=True)\n",
    "vehicle_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use `horsepower` alone to predict `mpg`, we get not-so-great results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='horsepower', y='mpg', data=vehicle_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we make a residual plot of the residuals versus the fitted values for this simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_simple = LinearRegression()\n",
    "model_simple.fit(vehicle_data[['horsepower']], vehicle_data['mpg'])\n",
    "model_simple_fitted = model_simple.predict(vehicle_data[['horsepower']])\n",
    "plt.scatter(model_simple_fitted, vehicle_data['mpg'] - model_simple_fitted)\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not an example of a \"good\" residual plot. There is an underlying parabolic pattern in the residuals, so we should consider adding a quadratic feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider including functions of existing features as new features to help improve the predictive power of our model. (This is something we will discuss in further detail in the Feature Engineering lecture, Lecture 14.) For example, the line below adds a column which contains the square of the horsepower for each car in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data['hp^2'] = vehicle_data['horsepower'] ** 2\n",
    "vehicle_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "Using scikit learn's `LinearRegression`, create and fit a model that tries to predict `mpg` from `horsepower` AND `hp^2`. Name your model `model_multiple`.\n",
    "\n",
    "- Hint: We do something very similar in Question 3.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple = LinearRegression()\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can see the coefficients and intercept. Note, there are now two elements in `model_multiple.coef_`, since there are two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "Using the above values, in LaTeX, write out the function that the model is using to predict `mpg` from `horsepower` and `hp^2`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the prediction of our model. It's much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL\n",
    "predicted_mpg = model_multiple.predict(vehicle_data[['horsepower', 'hp^2']])\n",
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data)\n",
    "plt.plot(vehicle_data['horsepower'],  predicted_mpg, color = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4c\n",
    "\n",
    "In the cell below, explain why we use the term \"linear\" to describe the model above, even though it incorporates horsepower squared as a feature.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4c\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see exactly how much better our new model is, we can compare the Multiple $R^2$ from these two fits.  As described in Lecture 12,\n",
    "\n",
    "\n",
    "$$R^2 = \\frac{\\text{variance of fitted values}}{\\text{variance of true } y} = \\frac{\\sigma_{\\hat{y}}^2}{\\sigma_y^2}$$\n",
    "\n",
    "Unlike $r$, the correlation coefficient we looked at in Question 1, $R^2$  can be used\n",
    "in the multiple regression setting.  In simple regression, $r^{2}$ and Multiple $R^{2}$ are\n",
    "the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mpg_horsepower_only = (\n",
    "    LinearRegression()\n",
    "    .fit(X = vehicle_data[['horsepower']], y = vehicle_data['mpg'])\n",
    "    .predict(vehicle_data[['horsepower']])\n",
    ")\n",
    "\n",
    "r2_horsepower_only = np.var(predicted_mpg_horsepower_only) / np.var(vehicle_data['mpg'])\n",
    "r2_both = np.var(predicted_mpg) / np.var(vehicle_data['mpg'])\n",
    "\n",
    "print('Multiple R^2 using only horsepower: ', r2_horsepower_only)\n",
    "print('Multiple R^2 using both horsepower and horsepower squared: ', r2_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By introducing `hp^2` as a feature, our multiple $R^2$ value increased. Think about what this means with respect to the strength of our refined model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4d\n",
    "\n",
    "In the cell below, we assign the mean of the `mpg` column of the `vehicle_data` dataframe to `mean_mpg`. Given this information, what is the mean of the `predicted_mpg` and `predicted_mpg_horsepower_only` arrays?\n",
    "\n",
    "Hint: You should not have to call `np.mean` in your code.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mpg = np.mean(vehicle_data['mpg'])\n",
    "mean_predicted_mpg = ...\n",
    "mean_predicted_mpg_horsepower_only = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Let's take this one step further, and introduce a few more features.\n",
    "\n",
    "\n",
    "Again, using scikit learn's `LinearRegression`, we fit a model that tries to predict `mpg` using each of the following as features:\n",
    "- `horsepower`\n",
    "- `hp^2`\n",
    "- `model_year`\n",
    "- `acceleration`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns = ['horsepower', 'hp^2', 'model_year', 'acceleration']\n",
    "model_many = LinearRegression()\n",
    "model_many.fit(X = vehicle_data[desired_columns], y= vehicle_data['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the prediction of our more sophisticated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_mpg_many = model_many.predict(vehicle_data[['horsepower', 'hp^2', 'model_year', 'acceleration']])\n",
    "sns.scatterplot(x='horsepower', y='mpg', data=vehicle_data)\n",
    "plt.plot(vehicle_data['horsepower'],  predicted_mpg_many, color = 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about what you see in the above plot. Why is the shape of our prediction curve so jagged? Do you think this is a good model to predict the `mpg` of some car we don't already have information on?\n",
    "\n",
    "This idea – the **bias-variance tradeoff** – is an idea we will explore in the coming weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5a\n",
    "\n",
    "Lastly, set `r2_many` to be the multiple $R^2$ coefficient obtained by using `model_many`.\n",
    "\n",
    "- Hint: This is very similar to what we did right before Question 4d. Use `predicted_mpg_many`.\n",
    "- Note: The above plotting cell needs to have been run in order for this to work.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_many = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multiple R^2 using only horsepower: ', r2_horsepower_only)\n",
    "print('Multiple R^2 using both horsepower and horsepower squared: ', r2_both)\n",
    "print('Multiple R^2 using horsepower, horsepower squared, model year, and acceleration: ', r2_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything was done correctly, the multiple $R^2$ of our latest model should be substantially higher than that of the previous two models. This is because multiple $R^2$ increases with the number of covariates we add to our model. \n",
    "\n",
    "We might not always want to use models with large multiple $R^2$ values because these models could be overfitting to the training data, and won't generalize well to unseen data. Again, this is an idea we will explore in future lectures and assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats, you finished the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
